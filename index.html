<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
		<title>Pose Pro Fixed</title>

		<style>
			html, body { margin: 0; padding: 0; width: 100%; height: 100%; background: #000; overflow: hidden; }
			video { position: absolute; inset: 0; width: 100%; height: 100%; object-fit: cover; z-index: 1; background: #000; }
			canvas { position: absolute; inset: 0; width: 100%; height: 100%; object-fit: cover; z-index: 2; pointer-events: none; }
			.mirror { transform: scaleX(-1); -webkit-transform: scaleX(-1); }
			#tip {
				position: absolute; top: 12px; left: 12px; z-index: 10;
				color: #4ec9b0; background: rgba(0, 0, 0, 0.7);
				padding: 6px 10px; border-radius: 4px;
				font-family: monospace; font-size: 12px;
			}
		</style>
	</head>

	<body>
		<div id="tip">System Initializing...</div>
		<video id="video" autoplay playsinline muted></video>
		<canvas id="canvas"></canvas>

		<script type="module">
			import { PoseLandmarker, FilesetResolver } from "/mediapipe/tasks-vision/vision_bundle.js";

			const video = document.getElementById("video");
			const canvas = document.getElementById("canvas");
			const ctx = canvas.getContext("2d");
			const tip = document.getElementById("tip");

			let poseLandmarker = null;
			let running = false;
			let facingMode = "user";

			/* ================= 1. 摄像头启动 (返回 Promise) ================= */
			async function startCamera() {
				if (video.srcObject) {
					video.srcObject.getTracks().forEach(t => t.stop());
				}

				try {
					const stream = await navigator.mediaDevices.getUserMedia({
						video: { facingMode, width: { ideal: 1280 }, height: { ideal: 720 } }
					});

					video.srcObject = stream;

					return new Promise((resolve) => {
						video.onloadedmetadata = () => {
							video.play();
							canvas.width = video.videoWidth;
							canvas.height = video.videoHeight;

							const mirror = facingMode === "user";
							video.classList.toggle("mirror", mirror);
							canvas.classList.toggle("mirror", mirror);

							running = true; 
							console.log("Camera hardware ready.");
							resolve();
						};
					});
				} catch (err) {
					tip.textContent = "Camera Error: " + err.message;
				}
			}

			/* ================= 2. AI 初始化 (独立运行) ================= */
			async function initAI() {
				try {
					const vision = await FilesetResolver.forVisionTasks("/mediapipe/tasks-vision/wasm");
					poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
						baseOptions: {
							modelAssetPath: "/mediapipe/model/pose_landmarker_lite.task",
							delegate: "GPU"
						},
						runningMode: "VIDEO",
						numPoses: 1
					});
					console.log("AI Model ready.");
					tip.textContent = "AI Ready";
				} catch (err) {
					console.error("AI Init Error:", err);
					tip.textContent = "AI Load Failed";
				}
			}

			/* ================= 3. 主渲染循环 ================= */
			function loop(ts) {
				requestAnimationFrame(loop);
				if (!running) return;

				ctx.clearRect(0, 0, canvas.width, canvas.height);

				// 如果 AI 还没加载完，loop 照常运行，但只跳过检测
				if (!poseLandmarker) return;

				const result = poseLandmarker.detectForVideo(video, ts);
				if (result.landmarks && result.landmarks.length > 0) {
					drawPose(result.landmarks[0]);
				}
			}

			/* ================= 4. 骨骼绘制 ================= */
			function drawPose(lm) {
				ctx.save();
				ctx.strokeStyle = "#00ff7f";
				ctx.fillStyle = "#ffffff";
				ctx.lineWidth = 3;
				ctx.lineCap = "round";
				
				const bones = [
					[11, 13], [13, 15], [12, 14], [14, 16],
					[23, 25], [25, 27], [24, 26], [26, 28],
					[11, 12], [23, 24], [11, 23], [12, 24]
				];

				bones.forEach(([a, b]) => {
					const start = { x: lm[a].x * canvas.width, y: lm[a].y * canvas.height };
					const end = { x: lm[b].x * canvas.width, y: lm[b].y * canvas.height };
					ctx.beginPath();
					ctx.moveTo(start.x, start.y);
					ctx.lineTo(end.x, end.y);
					ctx.stroke();
				});

				lm.forEach(p => {
					ctx.beginPath();
					ctx.arc(p.x * canvas.width, p.y * canvas.height, 3, 0, Math.PI * 2);
					ctx.fill();
				});
				ctx.restore();
			}

			/* ================= 5. 并行启动逻辑 ================= */
	/* ================= 优化后的启动逻辑 ================= */
async function main() {
    tip.textContent = "Loading Camera...";

    // 1. 第一优先级：先启动摄像头，让用户看到画面，心情不焦虑
    await startCamera(); 
    requestAnimationFrame(loop); 
    
    // 2. 关键优化：给浏览器 300ms 的“喘息时间”
    // 让摄像头渲染稳定下来，避开硬件调用的瞬时 CPU 峰值
    await new Promise(resolve => setTimeout(resolve, 300));

    // 3. 第二优先级：后台静默加载 AI
    tip.textContent = "Initializing AI Engine...";
    await initAI();
}

			main();

			/* --- 其它接口 --- */
			window.toggleCamera = async () => {
				facingMode = facingMode === "user" ? "environment" : "user";
				await startCamera();
				return facingMode;
			};
		</script>
	</body>
</html>