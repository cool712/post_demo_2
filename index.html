<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
  <title>Pose Detection Pro</title>

  <style>
    html, body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
      background: black;
      overflow: hidden;
    }

    video, canvas {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    /* ÈïúÂÉèÊ†∑ÂºèÔºöÁî± JS Âä®ÊÄÅÊ∑ªÂä†/ÁßªÈô§ */
    .mirror {
      transform: scaleX(-1);
      -webkit-transform: scaleX(-1);
    }

    canvas {
      pointer-events: none;
      z-index: 5;
    }

    #tip {
      position: absolute;
      top: 12px;
      left: 12px;
      color: #4ec9b0;
      font-size: 14px;
      font-family: monospace;
      z-index: 10;
      background: rgba(0,0,0,0.5);
      padding: 4px 8px;
      border-radius: 4px;
    }

    #switchBtn {
      position: absolute;
      bottom: 30px;
      right: 30px;
      width: 56px;
      height: 56px;
      background: rgba(255, 255, 255, 0.25);
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      z-index: 20;
      border: 2px solid white;
      color: white;
      font-size: 28px;
      backdrop-filter: blur(5px);
    }
  </style>
</head>

<body>
  <div id="tip">Starting...</div>
  <div id="switchBtn">üîÑ</div>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>

  <script type="module">
    import { PoseLandmarker, FilesetResolver } from "/mediapipe/tasks-vision/vision_bundle.js";

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d", { alpha: true });
    const tip = document.getElementById("tip");
    const switchBtn = document.getElementById("switchBtn");

    let poseLandmarker = null;
    let running = false;
    let currentFacingMode = "user"; // ÈªòËÆ§ÂâçÁΩÆ

    /* ---------------- Ê†∏ÂøÉÔºöÂêØÂä®/ÂàáÊç¢ÊëÑÂÉèÂ§¥ ---------------- */
    async function startCamera() {
      running = false; // ÂàáÊç¢ÊúüÈó¥ÊöÇÂÅú AI Âæ™ÁéØ
      
      // 1. ÂΩªÂ∫ïÂÅúÊ≠¢ÊóßÈü≥ËßÜÈ¢ëËΩ®ÈÅì (‰øÆÂ§çÂêéÁΩÆ‰∏çÂ∑•‰ΩúÁöÑÂÖ≥ÈîÆ)
      if (video.srcObject) {
        video.srcObject.getTracks().forEach(t => t.stop());
        video.srcObject = null;
      }

      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { 
            facingMode: currentFacingMode,
            width: { ideal: 1280 },
            height: { ideal: 720 }
          },
          audio: false
        });

        video.srcObject = stream;

        // 2. Â§ÑÁêÜÈïúÂÉèÊïàÊûúÔºöÂè™ÊúâÂâçÁΩÆÈúÄË¶ÅÈïúÂÉè
        if (currentFacingMode === "user") {
          video.classList.add("mirror");
          canvas.classList.add("mirror");
        } else {
          video.classList.remove("mirror");
          canvas.classList.remove("mirror");
        }

        // 3. Á≠âÂæÖËßÜÈ¢ëÂÖÉÊï∞ÊçÆÂä†ËΩΩÔºåÁ°Æ‰øùËé∑ÂèñÊ≠£Á°ÆÁöÑÂÆΩÈ´ò
        await new Promise(r => video.onloadedmetadata = r);
        await video.play();

        // 4. ‚≠ê Âä®ÊÄÅÂêåÊ≠•ÁîªÂ∏ÉÂ∞∫ÂØ∏ (‰øÆÂ§çÂêéÁΩÆÊçïÊçâ‰ΩçÁΩÆÂÅèÁßªÁöÑÂÖ≥ÈîÆ)
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        running = true;
        tip.textContent = `Active: ${currentFacingMode === 'user' ? 'Front' : 'Back'}`;
      } catch (err) {
        tip.textContent = "Error: " + err.message;
        console.error(err);
      }
    }

    /* ---------------- Ê†∏ÂøÉÔºöAI ÂàùÂßãÂåñ‰∏éÂæ™ÁéØ ---------------- */
    async function initPose() {
      const vision = await FilesetResolver.forVisionTasks("/mediapipe/tasks-vision/wasm");
      poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
        baseOptions: { 
          modelAssetPath: "/mediapipe/model/pose_landmarker_lite.task", 
          delegate: "GPU" 
        },
        runningMode: "VIDEO",
        numPoses: 1
      });
      tip.textContent = "Pose System Ready";
      requestAnimationFrame(loop);
    }

    function loop(ts) {
      if (running && poseLandmarker) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        
        // ÊâßË°åÊ£ÄÊµã
        const result = poseLandmarker.detectForVideo(video, ts);
        
        if (result.landmarks && result.landmarks[0]) {
          drawPose(result.landmarks[0]);
        }
      }
      requestAnimationFrame(loop);
    }

    /* ---------------- ÁªòÂõæËæÖÂä©ÂáΩÊï∞ ---------------- */
    function toCanvas(p) {
      return { x: p.x * canvas.width, y: p.y * canvas.height };
    }

    function calcAngle(a, b, c) {
      const ab = { x: a.x - b.x, y: a.y - b.y }, cb = { x: c.x - b.x, y: c.y - b.y };
      const dot = ab.x * cb.x + ab.y * cb.y;
      return Math.acos(dot / (Math.hypot(ab.x, ab.y) * Math.hypot(cb.x, cb.y))) * 180 / Math.PI;
    }

    function drawPose(lm) {
      ctx.save();
      ctx.strokeStyle = "#4ec9b0";
      ctx.fillStyle = "#ffffff";
      ctx.lineWidth = 4;

      const bones = [[11,13],[13,15],[12,14],[14,16],[23,25],[25,27],[24,26],[26,28],[11,12],[23,24],[11,23],[12,24]];
      bones.forEach(([a,b]) => {
        const p1 = toCanvas(lm[a]), p2 = toCanvas(lm[b]);
        ctx.beginPath(); ctx.moveTo(p1.x, p1.y); ctx.lineTo(p2.x, p2.y); ctx.stroke();
      });

      // Áîª‰∏ªË¶ÅÂÖ≥ËäÇÁÇπ
      lm.forEach((p, i) => {
        if (i < 11) return; // Ë∑≥ËøáÈù¢ÈÉ®
        const cp = toCanvas(p);
        ctx.beginPath(); ctx.arc(cp.x, cp.y, 4, 0, Math.PI * 2); ctx.fill();
      });

      // ÁîªËßíÂ∫¶
      [[11,13,15], [12,14,16], [23,25,27], [24,26,28]].forEach(([a,b,c]) => {
        const angle = Math.round(calcAngle(lm[a], lm[b], lm[c]));
        const p = toCanvas(lm[b]);
        ctx.font = "bold 16px monospace";
        ctx.fillStyle = "#4ec9b0";
        ctx.fillText(`${angle}¬∞`, p.x + 10, p.y - 10);
      });
      ctx.restore();
    }

    // ÊåâÈíÆ‰∫§‰∫í
    switchBtn.addEventListener('click', () => {
      currentFacingMode = (currentFacingMode === "user") ? "environment" : "user";
      startCamera();
    });

    // ÂêØÂä®
    startCamera();
    initPose();

    /* ---------------- ÂΩïÂà∂‰∏ä‰º†ÈÄªËæë (‰øùÁïôÂéüÊúâÂäüËÉΩ) ---------------- */
    let mediaRecorder;
    let recordedChunks = [];
    let recordStartTime;

    window.startRecord = async function () {
      if (!video.srcObject) return;
      recordedChunks = [];
      const mimeType = MediaRecorder.isTypeSupported("video/mp4") ? "video/mp4" : "video/webm;codecs=vp8";
      mediaRecorder = new MediaRecorder(video.srcObject, { mimeType });
      mediaRecorder.ondataavailable = e => { if (e.data.size > 0) recordedChunks.push(e.data); };
      recordStartTime = Date.now();
      mediaRecorder.start();
    };

    window.stopAndUpload = async function (url, token) {
      if (!mediaRecorder) return;
      mediaRecorder.onstop = async () => {
        const blob = new Blob(recordedChunks, { type: mediaRecorder.mimeType });
        const formData = new FormData();
        formData.append("file", blob, `rec_${Date.now()}.mp4`);
        formData.append("duration", (Date.now() - recordStartTime)/1000);
        try {
          const res = await fetch(url, { method: "POST", body: formData });
          window.flutter_inappwebview.callHandler("onUploadComplete", { success: res.ok });
        } catch (e) { console.error(e); }
      };
      mediaRecorder.stop();
    };
  </script>
</body>
</html>