<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
		<title>Pose Pro Fixed</title>
		<style>
			html, body { margin: 0; padding: 0; width: 100%; height: 100%; background: #000; overflow: hidden; }
			video { position: absolute; inset: 0; width: 100%; height: 100%; object-fit: cover; z-index: 1; background: #000; }
			canvas { position: absolute; inset: 0; width: 100%; height: 100%; object-fit: cover; z-index: 2; pointer-events: none; }
			.mirror { transform: scaleX(-1); -webkit-transform: scaleX(-1); }
			#tip { position: absolute; top: 12px; left: 12px; z-index: 10; color: #4ec9b0; background: rgba(0, 0, 0, 0.7); padding: 6px 10px; border-radius: 4px; font-family: monospace; font-size: 12px; }
		</style>
	</head>

	<body>
		<div id="tip">Initializing Camera...</div>
		<video id="video" autoplay playsinline muted></video>
		<canvas id="canvas"></canvas>

		<script type="module">
			import { PoseLandmarker, FilesetResolver } from "/mediapipe/tasks-vision/vision_bundle.js";

			const video = document.getElementById("video");
			const canvas = document.getElementById("canvas");
			const ctx = canvas.getContext("2d");
			const tip = document.getElementById("tip");

			let poseLandmarker = null;
			let running = false;
			let facingMode = "user";

			let dynamicScale = 0.5; 
			let frameCount = 0;
			let lastFpsCheck = 0;

			/* ================= 1. 摄像头启动 ================= */
			async function startCamera() {
				// 停止之前的流，释放硬件资源
				if (video.srcObject) {
					video.srcObject.getTracks().forEach(t => t.stop());
				}

				try {
					const stream = await navigator.mediaDevices.getUserMedia({
						video: {
							facingMode,
							width: { ideal: 1280 },
							height: { ideal: 720 }
						}
					});

					video.srcObject = stream;

					return new Promise((resolve) => {
						video.onloadedmetadata = () => {
							video.play();
							// 关键：切换镜头后必须重新同步画布尺寸，因为前后置分辨率可能不同
							canvas.width = video.videoWidth;
							canvas.height = video.videoHeight;

							const mirror = facingMode === "user";
							video.classList.toggle("mirror", mirror);
							canvas.classList.toggle("mirror", mirror);

							running = true; 
							resolve();
						};
					});
				} catch (err) {
					tip.textContent = "Camera Error: " + err.message;
					console.error(err);
				}
			}

			/* ================= 2. AI 初始化 ================= */
			async function initAI() {
				try {
					const vision = await FilesetResolver.forVisionTasks("/mediapipe/tasks-vision/wasm");
					poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
						baseOptions: {
							modelAssetPath: "/mediapipe/model/pose_landmarker_lite.task",
							delegate: "GPU"
						},
						runningMode: "VIDEO",
						numPoses: 1
					});
					tip.textContent = "AI Ready";
				} catch (err) {
					tip.textContent = "AI Load Failed";
				}
			}

			/* ================= 3. 主循环 ================= */
			function loop(ts) {
				requestAnimationFrame(loop);
				// 如果没有在运行或者模型还没加载，直接跳过
				if (!running || !poseLandmarker) return;

				ctx.clearRect(0, 0, canvas.width, canvas.height);

				frameCount++;
				if (ts - lastFpsCheck > 1000) {
					const fps = frameCount;
					if (fps < 12 && dynamicScale > 0.3) dynamicScale -= 0.1;
					else if (fps > 14 && dynamicScale < 1.0) dynamicScale += 0.1;
					tip.textContent = `Quality: ${Math.round(dynamicScale * 100)}% | FPS: ${fps}`;
					frameCount = 0;
					lastFpsCheck = ts;
				}

				try {
					// 只有在视频准备好且有数据时才检测
					if (video.readyState >= 2) {
						const result = poseLandmarker.detectForVideo(video, ts);
						if (result.landmarks && result.landmarks.length > 0) {
							drawPose(result.landmarks[0]);
						}
					}
				} catch (e) {
					// 捕获切换瞬间可能产生的底层错误
					console.warn("Detection skipped this frame:", e);
				}
			}

			/* ================= 4. 切换摄像头 (修复重点) ================= */
			window.toggleCamera = async () => {
				tip.textContent = "Switching Camera...";
				
				// 1. 先停止当前运行状态，清理画布
				running = false; 
				ctx.clearRect(0, 0, canvas.width, canvas.height);

				// 2. 切换模式
				facingMode = facingMode === "user" ? "environment" : "user";
				
				// 3. 重新启动摄像头
				await startCamera();
				
				// 4. 返回当前模式给 Flutter
				tip.textContent = `Camera OK (${facingMode})`;
				return facingMode;
			};

			/* ================= 绘制逻辑 ================= */
			function drawPose(lm) {
				ctx.save();
				ctx.strokeStyle = "#00ff7f";
				ctx.fillStyle = "#ffffff";
				ctx.lineWidth = 3;
				ctx.lineCap = "round";
				ctx.lineJoin = "round";

				const bones = [
					[11, 13], [13, 15], [12, 14], [14, 16],
					[23, 25], [25, 27], [24, 26], [26, 28],
					[11, 12], [23, 24], [11, 23], [12, 24]
				];

				bones.forEach(([a, b]) => {
					const pA = toCanvas(lm[a]);
					const pB = toCanvas(lm[b]);
					ctx.beginPath();
					ctx.moveTo(pA.x, pA.y);
					ctx.lineTo(pB.x, pB.y);
					ctx.stroke();
				});

				lm.forEach(p => {
					const pos = toCanvas(p);
					ctx.beginPath();
					ctx.arc(pos.x, pos.y, 3, 0, Math.PI * 2);
					ctx.fill();
				});

				drawAngle(lm[11], lm[13], lm[15]); 
				drawAngle(lm[12], lm[14], lm[16]); 
				drawAngle(lm[23], lm[25], lm[27]); 
				drawAngle(lm[24], lm[26], lm[28]); 

				ctx.restore();
			}

			function toCanvas(p) {
				return { x: p.x * canvas.width, y: p.y * canvas.height };
			}

			function calcAngle(a, b, c) {
				const ab = { x: a.x - b.x, y: a.y - b.y };
				const cb = { x: c.x - b.x, y: c.y - b.y };
				const dot = ab.x * cb.x + ab.y * cb.y;
				const mag1 = Math.hypot(ab.x, ab.y);
				const mag2 = Math.hypot(cb.x, cb.y);
				return Math.acos(dot / (mag1 * mag2)) * 180 / Math.PI;
			}

			function drawAngle(a, b, c) {
				if(!a || !b || !c) return;
				const angle = Math.round(calcAngle(a, b, c));
				const p = toCanvas(b);
				ctx.font = "12px monospace";
				ctx.fillText(`${angle}°`, p.x + 6, p.y - 6);
			}

			/* ================= 录制部分保持不变 ================= */
			let mediaRecorder;
			let recordedChunks = [];
			let startTime;

			window.startRecord = function() {
				recordedChunks = [];
				startTime = Date.now();
				mediaRecorder = new MediaRecorder(video.srcObject);
				mediaRecorder.ondataavailable = e => recordedChunks.push(e.data);
				mediaRecorder.start();
			};

			window.stopAndUpload = async function(uploadUrl, token) {
				if (!mediaRecorder) return;
				mediaRecorder.onstop = async () => {
					const duration = (Date.now() - startTime) / 1000;
					const blob = new Blob(recordedChunks, { type: mediaRecorder.mimeType });
					const formData = new FormData();
					const ext = mediaRecorder.mimeType.includes("mp4") ? "mp4" : "webm";
					formData.append("file", blob, `record_${Date.now()}.${ext}`);
					formData.append("duration", duration);
					try {
						const response = await fetch(uploadUrl, { method: "POST", body: formData });
						window.flutter_inappwebview.callHandler("onUploadComplete", {
							success: response.ok, status: response.status, duration: duration
						});
					} catch (err) {
						window.flutter_inappwebview.callHandler("onUploadComplete", { success: false, error: err.message });
					}
				};
				mediaRecorder.stop();
			};

			/* ================= 启动 ================= */
			async function main() {
				await startCamera();
				requestAnimationFrame(loop);
				initAI();
			}
			main();
		</script>
	</body>
</html>