<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
  <title>Optimized Mirror Pose</title>

  <style>
    html, body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
      background: black;
      overflow: hidden;
    }

    /* ⭐ 关键：同时对视频和画布进行水平镜像翻转 */
    video, canvas {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      transform: scaleX(-1);
      -webkit-transform: scaleX(-1);
    }

    /* 确保画布在视频上方 */
    canvas {
      z-index: 5;
      pointer-events: none;
    }

    video {
      z-index: 1;
    }

    #tip {
      position: absolute;
      top: 12px;
      left: 12px;
      color: #4ec9b0;
      font-size: 14px;
      font-family: monospace;
      z-index: 10;
      background: rgba(0,0,0,0.5);
      padding: 4px 8px;
      border-radius: 4px;
    }
  </style>
</head>

<body>
  <div id="tip">Initializing Mirror Mode…</div>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>

  <script type="module">
    /* ---------------- 1. 录制与上传逻辑 ---------------- */
    let mediaRecorder;
    let recordedChunks = [];
    let startTime;

    window.startRecord = async function () {
      if (!video.srcObject) return;
      recordedChunks = [];
      const mimeType = MediaRecorder.isTypeSupported("video/mp4") ? "video/mp4" : "video/webm;codecs=vp8";
      mediaRecorder = new MediaRecorder(video.srcObject, { mimeType });
      mediaRecorder.ondataavailable = e => { if (e.data.size > 0) recordedChunks.push(e.data); };
      startTime = Date.now();
      mediaRecorder.start();
    };

    window.stopAndUpload = async function (uploadUrl, token) {
      if (!mediaRecorder) return;
      mediaRecorder.onstop = async () => {
        const duration = (Date.now() - startTime) / 1000;
        const blob = new Blob(recordedChunks, { type: mediaRecorder.mimeType });
        const formData = new FormData();
        const ext = mediaRecorder.mimeType.includes("mp4") ? "mp4" : "webm";
        formData.append("file", blob, `record_${Date.now()}.${ext}`);
        formData.append("duration", duration);
        try {
          const response = await fetch(uploadUrl, { method: "POST", body: formData });
          window.flutter_inappwebview.callHandler("onUploadComplete", { 
            success: response.ok, 
            status: response.status 
          });
        } catch (err) {
          window.flutter_inappwebview.callHandler("onUploadComplete", { success: false });
        }
      };
      mediaRecorder.stop();
    };

    /* ---------------- 2. AI 逻辑与优化 ---------------- */
    import { PoseLandmarker, FilesetResolver } from "/mediapipe/tasks-vision/vision_bundle.js";

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    
    // ⭐ 修复：alpha 必须为 true 才能看到背后的视频
    const ctx = canvas.getContext("2d", { alpha: true }); 
    const tip = document.getElementById("tip");

    // 离屏优化
    const offscreenCanvas = document.createElement("canvas");
    const oCtx = offscreenCanvas.getContext("2d", { willReadFrequently: true });
    const PROCESS_WIDTH = 256; 

    let poseLandmarker = null;
    let running = false;

    function toCanvas(p) {
      return { x: p.x * canvas.width, y: p.y * canvas.height };
    }

    function calcAngle(a, b, c) {
      const ab = { x: a.x - b.x, y: a.y - b.y }, cb = { x: c.x - b.x, y: c.y - b.y };
      const dot = ab.x * cb.x + ab.y * cb.y;
      return Math.acos(dot / (Math.hypot(ab.x, ab.y) * Math.hypot(cb.x, cb.y))) * 180 / Math.PI;
    }

    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "user", width: { ideal: 1280 }, height: { ideal: 720 } },
        audio: false
      });
      video.srcObject = stream;
      await new Promise(r => video.onloadedmetadata = r);
      await video.play();
      
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      offscreenCanvas.width = PROCESS_WIDTH;
      offscreenCanvas.height = PROCESS_WIDTH * (video.videoHeight / video.videoWidth);
      running = true;
    }

    async function initPose() {
      const vision = await FilesetResolver.forVisionTasks("/mediapipe/tasks-vision/wasm");
      poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
        baseOptions: { modelAssetPath: "/mediapipe/model/pose_landmarker_lite.task", delegate: "GPU" },
        runningMode: "VIDEO",
        numPoses: 1
      });
      tip.textContent = "Mirror Mode Ready";
    }

    function loop(ts) {
      requestAnimationFrame(loop);
      if (!running || !poseLandmarker) return;

      // 1. 将视频帧画到离屏小画布进行 AI 检测
      oCtx.drawImage(video, 0, 0, offscreenCanvas.width, offscreenCanvas.height);

      // 2. 清空主画布（现在的 alpha: true 允许看到底层视频）
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      const result = poseLandmarker.detectForVideo(offscreenCanvas, ts);
      if (result.landmarks && result.landmarks.length > 0) {
        drawPose(result.landmarks[0]);
      }
    }

    function drawPose(lm) {
      ctx.save();
      ctx.strokeStyle = "#4ec9b0";
      ctx.fillStyle = "#ffffff";
      ctx.lineWidth = 3;

      const bones = [[11,13],[13,15],[12,14],[14,16],[23,25],[25,27],[24,26],[26,28],[11,12],[23,24],[11,23],[12,24]];
      bones.forEach(([a,b]) => {
        const p1 = toCanvas(lm[a]), p2 = toCanvas(lm[b]);
        ctx.beginPath(); ctx.moveTo(p1.x, p1.y); ctx.lineTo(p2.x, p2.y); ctx.stroke();
      });

      lm.forEach((p, i) => {
        if (i < 11) return; 
        const cp = toCanvas(p);
        ctx.beginPath(); ctx.arc(cp.x, cp.y, 2, 0, Math.PI * 2); ctx.fill();
      });

      [ [11,13,15], [12,14,16], [23,25,27], [24,26,28] ].forEach(([a,b,c]) => {
        const angle = Math.round(calcAngle(lm[a], lm[b], lm[c]));
        const p = toCanvas(lm[b]);
        ctx.font = "bold 14px monospace";
        ctx.fillStyle = "#4ec9b0";
        ctx.fillText(`${angle}°`, p.x + 8, p.y - 8);
      });
      ctx.restore();
    }

    startCamera();
    initPose();
    requestAnimationFrame(loop);
  </script>
</body>
</html>