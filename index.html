<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
  <title>Auto-Adaptive Pose Detection</title>
  <style>
    html, body { margin: 0; padding: 0; width: 100%; height: 100%; background: black; overflow: hidden; }
    video, canvas { position: absolute; inset: 0; width: 100%; height: 100%; object-fit: cover; }
    #tip { position: absolute; top: 12px; left: 12px; color: #4ec9b0; font-size: 12px; font-family: monospace; z-index: 10; opacity: 0.7; }
  </style>
</head>
<body>
  <div id="tip">AI 初始化中...</div>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>

  <script type="module">
    import { PoseLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const tip = document.getElementById("tip");

    let poseLandmarker = null;
    let currentStream = null;
    let mediaRecorder;
    let recordedChunks = [];
    
    // 自动调优配置
    let currentLevel = 'medium'; // 初始值
    const LEVELS = {
      low: { w: 480, h: 360 },
      medium: { w: 1280, h: 720 },
      high: { w: 1920, h: 1080 }
    };

    /* 核心：静默切换清晰度 */
    async function switchQuality(level) {
      if (currentLevel === level && currentStream) return;
      currentLevel = level;
      const { w, h } = LEVELS[level];

      try {
        if (currentStream) currentStream.getTracks().forEach(t => t.stop());
        currentStream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "environment", width: { ideal: w }, height: { ideal: h } },
          audio: false
        });
        video.srcObject = currentStream;
        await new Promise(r => video.onloadedmetadata = r);
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
      } catch (e) { console.error("Switch error", e); }
    }

    /* 录制接口 */
    window.startRecord = () => {
      recordedChunks = [];
      const stream = canvas.captureStream(30);
      mediaRecorder = new MediaRecorder(stream, { mimeType: MediaRecorder.isTypeSupported("video/mp4") ? "video/mp4" : "video/webm" });
      mediaRecorder.ondataavailable = e => recordedChunks.push(e.data);
      mediaRecorder.onstop = () => {
        const blob = new Blob(recordedChunks, { type: mediaRecorder.mimeType });
        const reader = new FileReader();
        reader.readAsDataURL(blob);
        reader.onloadend = () => {
          const base64 = reader.result.split(',')[1];
          window.flutter_inappwebview?.callHandler("onLocalSave", { base64, ext: mediaRecorder.mimeType.includes("mp4") ? "mp4" : "webm" });
        };
      };
      mediaRecorder.start();
    };

    window.stopRecord = () => mediaRecorder?.stop();

    /* 性能监控算法 */
    let lastTs = performance.now();
    let frames = 0;

    async function init() {
      await switchQuality('medium'); // 默认中等启动
      const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm");
      poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
        baseOptions: { modelAssetPath: "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task", delegate: "GPU" },
        runningMode: "VIDEO"
      });
      requestAnimationFrame(loop);
    }

    function loop(ts) {
      if (poseLandmarker && video.readyState >= 2) {
        frames++;
        // 每 3 秒自动评估一次性能
        if (ts - lastTs >= 3000) {
          const fps = (frames * 1000) / (ts - lastTs);
          if (fps < 12 && currentLevel !== 'low') switchQuality('low');
          else if (fps > 25 && currentLevel === 'low') switchQuality('medium');
          else if (fps > 28 && currentLevel === 'medium') switchQuality('high');
          
          tip.textContent = `Auto: ${currentLevel.toUpperCase()} | FPS: ${Math.round(fps)}`;
          frames = 0;
          lastTs = ts;
        }

        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        const result = poseLandmarker.detectForVideo(video, ts);
        if (result.landmarks.length > 0) {
          ctx.strokeStyle = "#4ec9b0"; ctx.lineWidth = 3;
          result.landmarks[0].forEach(p => {
            ctx.beginPath(); ctx.arc(p.x * canvas.width, p.y * canvas.height, 3, 0, 7); ctx.stroke();
          });
        }
      }
      requestAnimationFrame(loop);
    }
    init();
  </script>
</body>
</html>