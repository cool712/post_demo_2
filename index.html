<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
  <title>Pose Detection - Remote Control</title>
  <style>
    html, body { margin: 0; padding: 0; width: 100%; height: 100%; background: black; overflow: hidden; }
    video, canvas { position: absolute; inset: 0; width: 100%; height: 100%; object-fit: cover; }
    /* 镜像样式由 JS 动态控制 */
    .mirror { transform: scaleX(-1); -webkit-transform: scaleX(-1); }
    canvas { pointer-events: none; z-index: 5; }
    #tip { position: absolute; top: 12px; left: 12px; color: #4ec9b0; font-size: 12px; font-family: monospace; z-index: 10; background: rgba(0,0,0,0.5); padding: 4px 8px; border-radius: 4px; }
  </style>
</head>
<body>
  <div id="tip">AI System Initializing...</div>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>

  <script type="module">
    import { PoseLandmarker, FilesetResolver } from "/mediapipe/tasks-vision/vision_bundle.js";

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const tip = document.getElementById("tip");

    let poseLandmarker = null;
    let running = false;
    let currentFacingMode = "user"; 

    /* ---------------- 原生端调用的接口 ---------------- */

    /**
     * 1. 自动切换摄像头 (前置 <-> 后置)
     */
    window.toggleCamera = function() {
      currentFacingMode = (currentFacingMode === "user") ? "environment" : "user";
      startCamera();
    };

    /**
     * 2. 指定切换摄像头
     * @param {string} mode - "user" 或 "environment"
     */
    window.switchCameraTo = function(mode) {
      if (mode === "user" || mode === "environment") {
        currentFacingMode = mode;
        startCamera();
      }
    };

    /* ---------------- 核心：启动/切换摄像头 ---------------- */
    async function startCamera() {
      running = false; 
      tip.textContent = "Hardware Switching...";

      // 彻底清理旧流
      if (video.srcObject) {
        video.srcObject.getTracks().forEach(track => track.stop());
        video.srcObject = null;
      }

      // 给硬件 300ms 缓冲时间
      await new Promise(r => setTimeout(r, 300));

      const constraints = [
        { video: { facingMode: { exact: currentFacingMode }, width: { ideal: 1280 }, height: { ideal: 720 } } },
        { video: { facingMode: currentFacingMode, width: { ideal: 640 }, height: { ideal: 480 } } },
        { video: true }
      ];

      for (const constraint of constraints) {
        try {
          const stream = await navigator.mediaDevices.getUserMedia(constraint);
          video.srcObject = stream;
          
          // 处理镜像
          if (currentFacingMode === "user") {
            video.classList.add("mirror");
            canvas.classList.add("mirror");
          } else {
            video.classList.remove("mirror");
            canvas.classList.remove("mirror");
          }

          await new Promise(r => video.onloadedmetadata = r);
          await video.play();

          // 同步画布
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          
          running = true;
          tip.textContent = `Camera: ${currentFacingMode}`;
          return;
        } catch (e) {
          console.warn("Retrying constraints...", e);
        }
      }
      tip.textContent = "Camera switch failed";
    }

    /* ---------------- AI 逻辑 ---------------- */
    async function initPose() {
      const vision = await FilesetResolver.forVisionTasks("/mediapipe/tasks-vision/wasm");
      poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
        baseOptions: { modelAssetPath: "/mediapipe/model/pose_landmarker_lite.task", delegate: "GPU" },
        runningMode: "VIDEO",
        numPoses: 1
      });
      tip.textContent = "AI Active";
      requestAnimationFrame(loop);
    }

    function loop(ts) {
      if (running && poseLandmarker) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        const result = poseLandmarker.detectForVideo(video, ts);
        if (result.landmarks && result.landmarks[0]) {
          drawPose(result.landmarks[0]);
        }
      }
      requestAnimationFrame(loop);
    }

    function toCanvas(p) { return { x: p.x * canvas.width, y: p.y * canvas.height }; }
    function calcAngle(a, b, c) {
      const ab = { x: a.x - b.x, y: a.y - b.y }, cb = { x: c.x - b.x, y: c.y - b.y };
      const dot = ab.x * cb.x + ab.y * cb.y;
      return Math.acos(dot / (Math.hypot(ab.x, ab.y) * Math.hypot(cb.x, cb.y))) * 180 / Math.PI;
    }

    function drawPose(lm) {
      ctx.save();
      ctx.strokeStyle = "#4ec9b0";
      ctx.fillStyle = "#ffffff";
      ctx.lineWidth = 4;
      const bones = [[11,13],[13,15],[12,14],[14,16],[23,25],[25,27],[24,26],[26,28],[11,12],[23,24],[11,23],[12,24]];
      bones.forEach(([a,b]) => {
        const p1 = toCanvas(lm[a]), p2 = toCanvas(lm[b]);
        ctx.beginPath(); ctx.moveTo(p1.x, p1.y); ctx.lineTo(p2.x, p2.y); ctx.stroke();
      });
      lm.forEach((p, i) => { if (i >= 11) {
        const cp = toCanvas(p);
        ctx.beginPath(); ctx.arc(cp.x, cp.y, 4, 0, Math.PI * 2); ctx.fill();
      }});
      [[11,13,15], [12,14,16], [23,25,27], [24,26,28]].forEach(([a,b,c]) => {
        const angle = Math.round(calcAngle(lm[a], lm[b], lm[c]));
        const p = toCanvas(lm[b]);
        ctx.font = "bold 16px monospace";
        ctx.fillStyle = "#4ec9b0";
        ctx.fillText(`${angle}°`, p.x + 10, p.y - 10);
      });
      ctx.restore();
    }

    startCamera();
    initPose();

    /* --- 录制接口保持供 Flutter 调用 --- */
    let mediaRecorder;
    let recordedChunks = [];
    let recordStartTime;
    window.startRecord = async function() {
      recordedChunks = [];
      const mimeType = MediaRecorder.isTypeSupported("video/mp4") ? "video/mp4" : "video/webm;codecs=vp8";
      mediaRecorder = new MediaRecorder(video.srcObject, { mimeType });
      mediaRecorder.ondataavailable = e => { if (e.data.size > 0) recordedChunks.push(e.data); };
      recordStartTime = Date.now();
      mediaRecorder.start();
    };
    window.stopAndUpload = async function(url) {
      if (!mediaRecorder) return;
      mediaRecorder.onstop = async () => {
        const blob = new Blob(recordedChunks, { type: mediaRecorder.mimeType });
        const formData = new FormData();
        formData.append("file", blob, `rec_${Date.now()}.mp4`);
        formData.append("duration", (Date.now() - recordStartTime)/1000);
        await fetch(url, { method: "POST", body: formData });
        window.flutter_inappwebview.callHandler("onUploadComplete", { success: true });
      };
      mediaRecorder.stop();
    };
  </script>
</body>
</html>