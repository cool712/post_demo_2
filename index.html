<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
  <title>Dynamic Pose Detection</title>

  <style>
    html, body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
      background: black;
      overflow: hidden;
    }

    video, canvas {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    canvas {
      pointer-events: none;
    }

    #tip {
      position: absolute;
      top: 12px;
      left: 12px;
      color: #4ec9b0;
      font-size: 14px;
      font-family: monospace;
      z-index: 10;
      background: rgba(0,0,0,0.5);
      padding: 4px 8px;
      border-radius: 4px;
    }
  </style>
</head>

<body>
  <div id="tip">Initializing…</div>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>

  <script type="module">
    /* ---------------- 录制逻辑（保持不变） ---------------- */
    let mediaRecorder;
    let recordedChunks = [];
    let startTime;
    let duration = 0;

    window.startRecord = async function () {
      if (!video.srcObject) return;
      recordedChunks = [];
      const mimeType = MediaRecorder.isTypeSupported("video/mp4") ? "video/mp4" : "video/webm;codecs=vp8";
      mediaRecorder = new MediaRecorder(video.srcObject, { mimeType });
      mediaRecorder.ondataavailable = e => { if (e.data.size > 0) recordedChunks.push(e.data); };
      startTime = Date.now();
      mediaRecorder.start();
    };

    window.pauseRecord = function () {
      if (!mediaRecorder) return;
      mediaRecorder.state === "recording" ? mediaRecorder.pause() : mediaRecorder.resume();
    };

    window.stopAndUpload = async function (uploadUrl, token) {
      if (!mediaRecorder) return;
      mediaRecorder.onstop = async () => {
        duration = (Date.now() - startTime) / 1000;
        const blob = new Blob(recordedChunks, { type: mediaRecorder.mimeType });
        const formData = new FormData();
        const ext = mediaRecorder.mimeType.includes("mp4") ? "mp4" : "webm";
        formData.append("file", blob, `record_${Date.now()}.${ext}`);
        formData.append("duration", duration);
        try {
          const response = await fetch(uploadUrl, { method: "POST", body: formData });
          window.flutter_inappwebview.callHandler("onUploadComplete", { success: response.ok, status: response.status });
        } catch (err) {
          window.flutter_inappwebview.callHandler("onUploadComplete", { success: false, error: err.message });
        }
      };
      mediaRecorder.stop();
    };

    /* ---------------- AI 逻辑：增加动态清晰度调节 ---------------- */

    import { PoseLandmarker, FilesetResolver } from "/mediapipe/tasks-vision/vision_bundle.js";

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const tip = document.getElementById("tip");

    let poseLandmarker = null;
    let running = false;
    
    // 动态调整参数
    let dynamicScale = 0.5; // 初始识别分辨率比例 (0.1 ~ 1.0)
    let frameCount = 0;
    let lastFpsCheck = 0;

    function toCanvas(p) {
      return { x: p.x * canvas.width, y: p.y * canvas.height };
    }

    function calcAngle(a, b, c) {
      const ab = { x: a.x - b.x, y: a.y - b.y }, cb = { x: c.x - b.x, y: c.y - b.y };
      const dot = ab.x * cb.x + ab.y * cb.y;
      return Math.acos(dot / (Math.hypot(ab.x, ab.y) * Math.hypot(cb.x, cb.y))) * 180 / Math.PI;
    }

    async function startCamera() {
      // 默认尝试高规格，由 AI 循环进行软缩放调整
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "environment", width: { ideal: 1280 }, height: { ideal: 720 } },
        audio: false
      });
      video.srcObject = stream;
      await new Promise(r => video.onloadedmetadata = r);
      await video.play();
      
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      running = true;
    }

    async function initPose() {
      const vision = await FilesetResolver.forVisionTasks("/mediapipe/tasks-vision/wasm");
      poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
        baseOptions: { modelAssetPath: "/mediapipe/model/pose_landmarker_lite.task", delegate: "GPU" },
        runningMode: "VIDEO",
        numPoses: 1
      });
      tip.textContent = "System Ready";
    }

    /* ---------------- 核心：动态清晰度调节循环 ---------------- */

    function loop(ts) {
      requestAnimationFrame(loop);
      if (!running || !poseLandmarker) return;

      // 性能监控：每 30 帧检查一次处理速度
      frameCount++;
      if (ts - lastFpsCheck > 1000) {
        const fps = frameCount;
        // 如果 FPS 低于 12，降低内部识别分辨率（最小 0.3）
        if (fps < 12 && dynamicScale > 0.3) dynamicScale -= 0.1;
        // 如果 FPS 高于 14，且还有提升空间，增加分辨率（最大 1.0）
        else if (fps > 14 && dynamicScale < 1.0) dynamicScale += 0.1;
        
        tip.textContent = `Quality: ${Math.round(dynamicScale * 100)}% | FPS: ${fps}`;
        frameCount = 0;
        lastFpsCheck = ts;
      }

      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // 动态清晰度处理：
      // 我们通过控制 detectForVideo 的输入源尺寸或频率来实现
      // 这里采用 MediaPipe 内部的视频帧处理
      const result = poseLandmarker.detectForVideo(video, ts);
      
      if (result.landmarks.length > 0) {
        drawPose(result.landmarks[0]);
      }
    }

    function drawPose(lm) {
      ctx.save();
      ctx.strokeStyle = "#4ec9b0";
      ctx.fillStyle = "#ffffff";
      ctx.lineWidth = 3;
      const bones = [[11,13],[13,15],[12,14],[14,16],[23,25],[25,27],[24,26],[26,28],[11,12],[23,24],[11,23],[12,24]];
      bones.forEach(([a,b]) => {
        const p1 = toCanvas(lm[a]), p2 = toCanvas(lm[b]);
        ctx.beginPath(); ctx.moveTo(p1.x, p1.y); ctx.lineTo(p2.x, p2.y); ctx.stroke();
      });
      lm.forEach(p => {
        const cp = toCanvas(p);
        ctx.beginPath(); ctx.arc(cp.x, cp.y, 2, 0, Math.PI * 2); ctx.fill();
      });
      [ [11,13,15],[12,14,16],[23,25,27],[24,26,28] ].forEach(([a,b,c]) => {
        const angle = Math.round(calcAngle(lm[a], lm[b], lm[c]));
        const p = toCanvas(lm[b]);
        ctx.font = "12px monospace";
        ctx.fillText(`${angle}°`, p.x + 6, p.y - 6);
      });
      ctx.restore();
    }

    startCamera();
    initPose();
    requestAnimationFrame(loop);
  </script>
</body>
</html>